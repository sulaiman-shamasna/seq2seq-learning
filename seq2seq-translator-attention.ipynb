{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93a38f66-a16c-4aa6-b33a-43a1c38995fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "\n",
    "def fix_random_seed(seed):\n",
    "    \"\"\" Setting the random seed of various libraries \"\"\"\n",
    "    try:\n",
    "        np.random.seed(seed)\n",
    "    except NameError:\n",
    "        print(\"Warning: Numpy is not imported. Setting the seed for Numpy failed.\")\n",
    "    try:\n",
    "        tf.random.set_seed(seed)\n",
    "    except NameError:\n",
    "        print(\"Warning: TensorFlow is not imported. Setting the seed for TensorFlow failed.\")\n",
    "    try:\n",
    "        random.seed(seed)\n",
    "    except NameError:\n",
    "        print(\"Warning: random module is not imported. Setting the seed for random failed.\")\n",
    " \n",
    "# Fixing the random seed\n",
    "random_seed=4321\n",
    "fix_random_seed(random_seed)\n",
    "\n",
    "print(\"TensorFlow version: {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6380ead-cc47-4e35-bb07-6d22a5be54cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TF_FORCE_GPU_ALLOW_GROWTH=true\n"
     ]
    }
   ],
   "source": [
    "# Not setting this led to the following error\n",
    "# _Derived_]RecvAsync is cancelled.   \n",
    "# [[{{node gradient_tape/model_1/embedding_1/embedding_lookup/Reshape/_172}}]] [Op:__inference_train_function_31985]\n",
    "\n",
    "%env TF_FORCE_GPU_ALLOW_GROWTH=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a201b813-5b9c-4653-bc00-1f74d26f11bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The extracted data already exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "# Make sure the zip file has been downloaded\n",
    "if not os.path.exists(os.path.join('data','deu-eng.zip')):\n",
    "    raise FileNotFoundError(\n",
    "        \"Uh oh! Did you download the deu-eng.zip from http://www.manythings.org/anki/deu-eng.zip manually and place it in the Ch11/data folder?\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    if not os.path.exists(os.path.join('data', 'deu.txt')):\n",
    "        with zipfile.ZipFile(os.path.join('data','deu-eng.zip'), 'r') as zip_ref:\n",
    "            zip_ref.extractall('data')\n",
    "    else:\n",
    "        print(\"The extracted data already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25db97fc-fe57-462b-a975-c2f6bdfcf911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.shape = (277891, 2)\n",
      "(clean) df.shape = (277205, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the csv file\n",
    "df = pd.read_csv(os.path.join('data', 'deu.txt'), delimiter='\\t', header=None)\n",
    "# Set column names\n",
    "df.columns = [\"EN\", \"DE\", \"Attribution\"]\n",
    "df = df[[\"EN\", \"DE\"]]\n",
    "print('df.shape = {}'.format(df.shape))\n",
    "\n",
    "clean_inds = [i for i in range(len(df)) if b\"\\xc2\" not in df.iloc[i][\"DE\"].encode(\"utf-8\")]\n",
    "df = df.iloc[clean_inds]\n",
    "\n",
    "print('(clean) df.shape = {}'.format(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77269af0-7ab7-4385-a16e-38954ca94cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EN</th>\n",
       "      <th>DE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>277882</th>\n",
       "      <td>Remember that the purpose of the Tatoeba Proje...</td>\n",
       "      <td>Es gilt zu bedenken, dass es das Anliegen des ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277883</th>\n",
       "      <td>When I was younger, I hated going to weddings....</td>\n",
       "      <td>Als ich jünger war, hasste ich es, auf Hochzei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277884</th>\n",
       "      <td>If someone who doesn't know your background sa...</td>\n",
       "      <td>Wenn jemand, der deine Herkunft nicht kennt, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277885</th>\n",
       "      <td>If someone who doesn't know your background sa...</td>\n",
       "      <td>Wenn jemand Fremdes dir sagt, dass du dich wie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277887</th>\n",
       "      <td>If someone who doesn't know your background sa...</td>\n",
       "      <td>Wenn einem von jemandem, der nicht weiß, woher...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       EN  \\\n",
       "277882  Remember that the purpose of the Tatoeba Proje...   \n",
       "277883  When I was younger, I hated going to weddings....   \n",
       "277884  If someone who doesn't know your background sa...   \n",
       "277885  If someone who doesn't know your background sa...   \n",
       "277887  If someone who doesn't know your background sa...   \n",
       "\n",
       "                                                       DE  \n",
       "277882  Es gilt zu bedenken, dass es das Anliegen des ...  \n",
       "277883  Als ich jünger war, hasste ich es, auf Hochzei...  \n",
       "277884  Wenn jemand, der deine Herkunft nicht kennt, s...  \n",
       "277885  Wenn jemand Fremdes dir sagt, dass du dich wie...  \n",
       "277887  Wenn einem von jemandem, der nicht weiß, woher...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "528cc3ca-0fb4-4047-a0b9-122e10418768",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 50000\n",
    "df = df.sample(n=n_samples, random_state=random_seed)\n",
    "\n",
    "start_token = 'sos'\n",
    "end_token = 'eos'\n",
    "\n",
    "df[\"DE\"] = start_token + ' ' + df[\"DE\"] + ' ' + end_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e04dcb70-a0d6-4a7f-9fc3-8cf608db2b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_df.shape = (5000, 2)\n",
      "valid_df.shape = (5000, 2)\n",
      "train_df.shape = (40000, 2)\n"
     ]
    }
   ],
   "source": [
    "# Randomly sample 5000 examples from the total 50000 randomly\n",
    "test_df = df.sample(n=int(n_samples/10), random_state=random_seed)\n",
    "# Randomly sample 5000 examples from the total 50000 randomly\n",
    "valid_df = df.loc[~df.index.isin(test_df.index)].sample(n=int(n_samples/10), random_state=random_seed)\n",
    "# Assign the rest to training data\n",
    "train_df = df.loc[~(df.index.isin(test_df.index) | df.index.isin(valid_df.index))]\n",
    "\n",
    "print('test_df.shape = {}'.format(test_df.shape))\n",
    "print('valid_df.shape = {}'.format(valid_df.shape))\n",
    "print('train_df.shape = {}'.format(train_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857b57cc-5fb9-4a91-99da-0cb2a1a01826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Create a flattened list from English words\n",
    "en_words = train_df[\"EN\"].str.split().sum()\n",
    "# Create a flattened list of German words\n",
    "de_words = train_df[\"DE\"].str.split().sum()\n",
    "\n",
    "# Get the vocabulary size of words appearing more than or equal to 10 times\n",
    "n=10\n",
    "\n",
    "def get_vocabulary_size_greater_than(words, n, verbose=True):\n",
    "    \n",
    "    \"\"\" Get the vocabulary size above a certain threshold \"\"\"\n",
    "    \n",
    "    # Generate a counter object i.e. dict word -> frequency\n",
    "    counter = Counter(words)\n",
    "    \n",
    "    # Create a pandas series from the counter, then sort most frequent to least\n",
    "    freq_df = pd.Series(list(counter.values()), index=list(counter.keys())).sort_values(ascending=False)\n",
    "    \n",
    "    if verbose:\n",
    "        # Print most common words\n",
    "        print(freq_df.head(n=10))\n",
    "\n",
    "    # Count of words >= n frequent    \n",
    "    n_vocab = (freq_df>=n).sum()\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\nVocabulary size (>={} frequent): {}\".format(n, n_vocab))\n",
    "        \n",
    "    return n_vocab\n",
    "\n",
    "print(\"English corpus\")\n",
    "print('='*50)\n",
    "en_vocab = get_vocabulary_size_greater_than(en_words, n)\n",
    "\n",
    "print(\"\\nGerman corpus\")\n",
    "print('='*50)\n",
    "de_vocab = get_vocabulary_size_greater_than(de_words, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2ba71b-8a1f-4c1f-87ce-aae9ab1a3c84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb736a8d-5d7a-42fd-b626-f411f959cab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5292f2e5-e515-414c-a192-159533601943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32efdea4-ad20-459e-ba60-19168b38c22c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988c27b8-0eb8-4356-bc08-47af714bb046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23550195-0b5c-4ddb-817f-401051eb0dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f0cafd-6852-4317-a7a9-dd63b5ff1e21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaa660c-431a-468d-ba5a-7491b9ac9f58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc453d8-22f5-416a-a35f-e4f48505bd90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
